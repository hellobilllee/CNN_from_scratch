{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-13-a28fe5aba314>:5: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From c:\\users\\admin\\anaconda3\\envs\\py35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From c:\\users\\admin\\anaconda3\\envs\\py35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\users\\admin\\anaconda3\\envs\\py35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\users\\admin\\anaconda3\\envs\\py35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\users\\admin\\anaconda3\\envs\\py35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "(55000, 784) (55000, 10)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# MNIST_data指的是存放数据的文件夹路径，one_hot=True 为采用one_hot的编码方式编码标签\n",
    "mnist = input_data.read_data_sets('MNIST_data',one_hot=True)\n",
    "\n",
    "#load data\n",
    "train_X = mnist.train.images                #训练集样本\n",
    "validation_X = mnist.validation.images      #验证集样本\n",
    "test_X = mnist.test.images                  #测试集样本\n",
    "#labels\n",
    "train_Y = mnist.train.labels                #训练集标签\n",
    "validation_Y = mnist.validation.labels      #验证集标签\n",
    "test_Y = mnist.test.labels                  #测试集标签\n",
    "\n",
    "print(train_X.shape,train_Y.shape)          #输出训练集样本和标签的大小\n",
    "\n",
    "#查看数据，例如训练集中第一个样本的内容和标签\n",
    "#print(train_X[0])       #是一个包含784个元素且值在[0,1]之间的向量\n",
    "#print(train_Y[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#可视化样本\n",
    "img = train_X[0].reshape(28, 28)\n",
    "print(img.shape)\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2880x1440 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure,axes = plt.subplots(2, 3, figsize=[40,20])\n",
    "axes = axes.flatten()\n",
    "for i in range(6):\n",
    "    img = train_X[i].reshape(28, 28)\n",
    "    axes[i].imshow(img,cmap='Greys')\n",
    "axes[0].set_xticks([])\n",
    "axes[0].set_yticks([])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLayer:\n",
    "  # 卷积层，输入包含四个参数，这里默认使用valid padding，即不对输入做padding\n",
    "    def __init__(self, num_filters, length, width, stride):\n",
    "        \"\"\"\n",
    "        num_filters: 卷积核个数\n",
    "        length：     卷积核长\n",
    "        width：      卷积核宽\n",
    "        stride：     卷积核步长\n",
    "        \"\"\"\n",
    "        self.num_filters = num_filters\n",
    "        self.length = length\n",
    "        self.width = width\n",
    "        self.stride = stride\n",
    "        # 所有卷积参数构成一个3维矩阵， (num_filters, lenght, width)\n",
    "        # 参数随机初始化，除length*width减小方差\n",
    "        self.filters = np.random.randn(num_filters, length, width) / (length*width)\n",
    "        \n",
    "    def iterate_regions(self, image):\n",
    "        \"\"\"\n",
    "        输入： image，单通道图片矩阵\n",
    "        输出： (im_region, i, j), 所有length x width 大小的图片区域及对应位置索引\n",
    "        \"\"\"\n",
    "        h, w = image.shape\n",
    "        h_new = (h-self.length) // self.stride + 1\n",
    "        w_new = (w-self.width) // self.stride + 1\n",
    "        for i in range(h_new):\n",
    "            for j in range(w_new):\n",
    "                im_region = image[i*self.stride:(i*self.stride + self.length), j*self.stride:(j*self.stride + self.width)]\n",
    "                yield im_region, i, j\n",
    "                \n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        输入： input， 二维矩阵\n",
    "        输出：(h_new, w_new, num_filters)， 三维卷积输出\n",
    "        \"\"\"\n",
    "        h, w = input.shape\n",
    "        h_new = (h-self.length) // self.stride + 1\n",
    "        w_new = (w-self.width) // self.stride + 1\n",
    "        output = np.zeros((h_new, w_new, self.num_filters))\n",
    "        for im_region, i, j in self.iterate_regions(input):\n",
    "            output[i, j] = np.sum(im_region * self.filters, axis=(1, 2))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPoolingLayer:\n",
    "  # 池化层\n",
    "    def __init__(self, num_filters, length, width, stride):\n",
    "        \"\"\"\n",
    "        num_filters: 池化核个数\n",
    "        length：     池化核长\n",
    "        width：      池化核宽\n",
    "        stride：     池化核步长\n",
    "        \"\"\"\n",
    "        self.num_filters = num_filters\n",
    "        self.length = length\n",
    "        self.width = width\n",
    "        self.stride = stride\n",
    "        \n",
    "    def iterate_regions(self, image):\n",
    "        \"\"\"\n",
    "        输入： image，二维矩阵\n",
    "        输出： (im_region, i, j), 所有length x width 大小的矩阵区域及对应位置索引\n",
    "        \"\"\"\n",
    "        h, w, _ = image.shape\n",
    "        h_new = (h-self.length) // self.stride + 1\n",
    "        w_new = (w-self.width) // self.stride + 1\n",
    "        for i in range(h_new):\n",
    "            for j in range(w_new):\n",
    "                im_region = image[(i * self.stride):(i * self.stride + self.length), (j * self.stride):(j * self.stride + self.width)]\n",
    "                yield im_region, i, j\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        input: (h, w, num_filters),3维矩阵\n",
    "        output: (h / 2, w / 2, num_filters).\n",
    "        \"\"\"\n",
    "        h, w, num_filters = input.shape\n",
    "        h_new = (h-self.length) // self.stride + 1\n",
    "        w_new = (w-self.width) // self.stride + 1\n",
    "        output = np.zeros((h_new, w_new, num_filters))\n",
    "        for im_region, i, j in self.iterate_regions(input):\n",
    "            output[i, j] = np.amax(im_region, axis=(0, 1))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxLayer:\n",
    "  # 全连接层带softmax激活函数.\n",
    "    def __init__(self, input_len, nodes):\n",
    "        # 参随机数初始化\n",
    "        self.weights = np.random.randn(input_len, nodes) / input_len\n",
    "        self.biases = np.zeros(nodes)\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        input：input can be any array with any dimensions \n",
    "        output：一维数组，表示各类别概率\n",
    "        \"\"\"\n",
    "        input = input.flatten()\n",
    "\n",
    "        input_len, nodes = self.weights.shape\n",
    "\n",
    "        totals = np.dot(input, self.weights) + self.biases\n",
    "        exp = np.exp(totals)\n",
    "        return exp / np.sum(exp, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxLayer:\n",
    "  # 全连接层带softmax激活函数.\n",
    "\n",
    "    def __init__(self, input_len, nodes):\n",
    "        # 参随机数初始化\n",
    "        self.weights = np.random.randn(input_len, nodes) / input_len\n",
    "        self.biases = np.zeros(nodes)\n",
    "        \n",
    "    def backprop(self, d_L_d_out, learning_rate):\n",
    "        \"\"\"\n",
    "        input: (d_L_d_out,learning_rate), (损失对输出结果的导数,学习率)\n",
    "        output: d_L_d_inputs， 损失对输入数据的导数\n",
    "        \"\"\"\n",
    "        # d_L_d_out当中只有真实标签所在位置数值不为0\n",
    "        for i, gradient in enumerate(d_L_d_out):\n",
    "            if gradient == 0:\n",
    "                continue\n",
    "\n",
    "            # e^totals\n",
    "            t_exp = np.exp(self.last_totals)\n",
    "\n",
    "            # Sum of all e^totals\n",
    "            S = np.sum(t_exp)\n",
    "\n",
    "            # out[i] 对输出求导\n",
    "            d_out_d_t = -t_exp[i] * t_exp / (S ** 2)\n",
    "            d_out_d_t[i] = t_exp[i] * (S - t_exp[i]) / (S ** 2)\n",
    "\n",
    "            # 输出对 weights/biases/input 的梯度\n",
    "            d_t_d_w = self.last_input\n",
    "            d_t_d_b = 1\n",
    "            d_t_d_inputs = self.weights\n",
    "\n",
    "            # 损失对输出的梯度\n",
    "            d_L_d_t = gradient * d_out_d_t\n",
    "\n",
    "            # 链式法则求损失对weights/biases/input 的梯度\n",
    "            d_L_d_w = d_t_d_w[np.newaxis].T @ d_L_d_t[np.newaxis]\n",
    "            d_L_d_b = d_L_d_t * d_t_d_b\n",
    "            d_L_d_inputs = d_t_d_inputs @ d_L_d_t\n",
    "\n",
    "            # 更新 weights / biases\n",
    "            self.weights -= learning_rate * d_L_d_w\n",
    "            self.biases -= learning_rate * d_L_d_b\n",
    "        return d_L_d_inputs.reshape(self.last_input_shape)\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        input：input can be any array with any dimensions \n",
    "        output：一维数组，表示各类别概率\n",
    "        \"\"\"\n",
    "        self.last_input_shape = input.shape\n",
    "        \n",
    "        input = input.flatten()\n",
    "        self.last_input = input\n",
    "        \n",
    "        input_len, nodes = self.weights.shape\n",
    "\n",
    "        totals = np.dot(input, self.weights) + self.biases\n",
    "        \n",
    "        self.last_totals = totals\n",
    "        \n",
    "        exp = np.exp(totals)\n",
    "        return exp / np.sum(exp, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPoolingLayer:\n",
    "  # A Max Pooling layer .\n",
    "    def __init__(self, num_filters, length, width, stride):\n",
    "        self.num_filters = num_filters\n",
    "        self.length = length\n",
    "        self.width = width\n",
    "        self.stride = stride\n",
    "        \n",
    "    def iterate_regions(self, image):\n",
    "        \"\"\"\n",
    "        输入： image，二维矩阵\n",
    "        输出： (im_region, i, j), 所有length x width 大小的矩阵区域及对应位置索引\n",
    "        \"\"\"\n",
    "        h, w, _ = image.shape\n",
    "        h_new = (h-self.length) // self.stride + 1\n",
    "        w_new = (w-self.width) // self.stride + 1\n",
    "        for i in range(h_new):\n",
    "            for j in range(w_new):\n",
    "                im_region = image[(i * self.stride):(i * self.stride + self.length), (j * self.stride):(j * self.stride + self.width)]\n",
    "                yield im_region, i, j\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        输入： image，二维矩阵\n",
    "        输出： (im_region, i, j), 所有length x width 大小的矩阵区域及对应位置索引\n",
    "        \"\"\"\n",
    "        h, w, num_filters = input.shape\n",
    "        self.last_input = input\n",
    "        \n",
    "        h_new = (h-self.length) // self.stride + 1\n",
    "        w_new = (w-self.width) // self.stride + 1\n",
    "        output = np.zeros((h_new, w_new, num_filters))\n",
    "\n",
    "        for im_region, i, j in self.iterate_regions(input):\n",
    "            output[i, j] = np.amax(im_region, axis=(0, 1))\n",
    "        return output\n",
    "    def backprop(self, d_L_d_out):\n",
    "        \"\"\"\n",
    "        input: (h, w, num_filters),3维矩阵\n",
    "        output: (h / 2, w / 2, num_filters).\n",
    "        \"\"\"\n",
    "        d_L_d_input = np.zeros(self.last_input.shape)\n",
    "\n",
    "        for im_region, i, j in self.iterate_regions(self.last_input):\n",
    "            h, w, f = im_region.shape\n",
    "            amax = np.amax(im_region, axis=(0, 1))\n",
    "\n",
    "            for i2 in range(h):\n",
    "                for j2 in range(w):\n",
    "                    for f2 in range(f):\n",
    "                        # If this pixel was the max value, copy the gradient to it.\n",
    "                        if im_region[i2, j2, f2] == amax[f2]:\n",
    "                            d_L_d_input[i * self.length + i2, j * self.width + j2, f2] = d_L_d_out[i, j, f2]\n",
    "\n",
    "        return d_L_d_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class ConvLayer:\n",
    "  # A Convolution layer\n",
    "    def __init__(self, num_filters, length, width, stride):\n",
    "        \"\"\"\n",
    "        num_filters: 卷积核个数\n",
    "        length：     卷积核长\n",
    "        width：      卷积核宽\n",
    "        stride：     卷积核步长\n",
    "        \"\"\"\n",
    "        self.num_filters = num_filters\n",
    "        self.length = length\n",
    "        self.width = width\n",
    "        self.stride = stride\n",
    "\n",
    "        # 所有卷积参数构成一个3维矩阵， (num_filters, lenght, width)\n",
    "        # 参数随机初始化，除length*width减小方差\n",
    "        self.filters = np.random.randn(num_filters, length, width) / (length*width)\n",
    "    def iterate_regions(self, image):\n",
    "        \"\"\"\n",
    "        输入： image，二维矩阵\n",
    "        输出： (im_region, i, j), 所有length x width 大小的矩阵区域及对应位置索引\n",
    "        \"\"\"\n",
    "        h, w = image.shape\n",
    "        h_new = (h-self.length) // self.stride + 1\n",
    "        w_new = (w-self.width) // self.stride + 1\n",
    "        for i in range(h_new):\n",
    "            for j in range(w_new):\n",
    "                im_region = image[i*self.stride:(i*self.stride + self.length), j*self.stride:(j*self.stride + self.width)]\n",
    "                yield im_region, i, j\n",
    "    def backprop(self, d_L_d_out, learning_rate):\n",
    "        \"\"\"\n",
    "        input: (d_L_d_out,learning_rate), (损失对输出结果的导数,学习率)\n",
    "        output: d_L_d_inputs， 损失对输入数据的导数\n",
    "        \"\"\"\n",
    "        d_L_d_filters = np.zeros(self.filters.shape)\n",
    "\n",
    "        for im_region, i, j in self.iterate_regions(self.last_input):\n",
    "            for f in range(self.num_filters):\n",
    "                d_L_d_filters[f] += d_L_d_out[i, j, f] * im_region\n",
    "\n",
    "        # 更新卷积参数\n",
    "        self.filters -= learning_rate * d_L_d_filters\n",
    "\n",
    "        return None\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        输入： input， 二维矩阵\n",
    "        输出：(h_new, w_new, num_filters)， 三维卷积输出\n",
    "        \"\"\"\n",
    "        h, w = input.shape\n",
    "        self.last_input = input\n",
    "        h_new = (h-self.length) // self.stride + 1\n",
    "        w_new = (w-self.width) // self.stride + 1\n",
    "        output = np.zeros((h_new, w_new, self.num_filters))\n",
    "\n",
    "        for im_region, i, j in self.iterate_regions(input):\n",
    "            output[i, j] = np.sum(im_region * self.filters, axis=(1, 2))\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_X.reshape(-1,28,28)\n",
    "train_labels = train_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 28, 28)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 10)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 28, 28)\n",
      "(26, 26, 8)\n",
      "(13, 13, 8)\n",
      "[0.0996198  0.09935521 0.10001763 0.10086373 0.10009909 0.10006213\n",
      " 0.10030417 0.09980881 0.0996551  0.10021434]\n"
     ]
    }
   ],
   "source": [
    "train_images = train_X.reshape(-1,28,28)\n",
    "train_labels = train_Y\n",
    "print(train_images.shape)\n",
    "conv = ConvLayer(8,3,3,1)\n",
    "output = conv.forward(train_images[0])\n",
    "print(output.shape) # (26, 26, 8)\n",
    "pool = MaxPoolLayer(8,2,2,2)\n",
    "output = pool.forward(output)\n",
    "print(output.shape) # (13, 13, 8)\n",
    "softmax = SoftmaxLayer(13 * 13 * 8, 10) # 13x13x8 -> 10\n",
    "out = softmax.forward(output)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 13, 8)\n"
     ]
    }
   ],
   "source": [
    "pool = MaxPoolLayer(8,2,2,2)\n",
    "output = pool.forward(output)\n",
    "print(output.shape) # (13, 13, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2 = ConvLayer(8,3,3,1)\n",
    "output = conv2.forward(train_images[0])\n",
    "print(output.shape) # (26, 26, 8)\n",
    "softmax = SoftmaxLayer(13 * 13 * 8, 10) # 13x13x8 -> 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = SoftmaxLayer(13 * 13 * 8, 10) # 13x13x8 -> 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = softmax.forward(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10021889 0.1002936  0.10020267 0.09935552 0.09988143 0.09961841\n",
      " 0.10033022 0.10010283 0.10044285 0.09955357]\n"
     ]
    }
   ],
   "source": [
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09974709011389524"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(out*train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 28, 28) (1000, 10)\n",
      "(1000, 28, 28) (1000, 10)\n"
     ]
    }
   ],
   "source": [
    "# demo使用一千张图片做训练与测试， 可以使用全部的训练和测试图片，训练时间会比较久一些\n",
    "train_images = train_X.reshape(-1,28,28)[:1000]\n",
    "train_labels = train_Y[:1000]\n",
    "\n",
    "test_images = test_X.reshape(-1,28,28)[:1000]\n",
    "test_labels = test_Y[:1000]\n",
    "\n",
    "print(train_images.shape, train_labels.shape)\n",
    "print(test_images.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = ConvLayer(8,3,3,1)                  # 28x28x1 -> 26x26x8\n",
    "pool = MaxPoolingLayer(8,2,2,2)                  # 26x26x8 -> 13x13x8\n",
    "softmax = SoftmaxLayer(13 * 13 * 8, 10) # 13x13x8 -> 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(image, label):\n",
    "    \"\"\"\n",
    "    CNN 前向传播并计算 accuracy 与 cross-entropy loss.\n",
    "    - image： 2d numpy array\n",
    "    - label： one-hot encoded digit\n",
    "    \"\"\"\n",
    "    \n",
    "    # 将图片像素值从 [0, 255] 转换到 [-0.5, 0.5] ，这样更便于网络进行训练\n",
    "    out = conv.forward((image / 255.0) - 0.5)\n",
    "    out = pool.forward(out)\n",
    "    out = softmax.forward(out)\n",
    "\n",
    "    # Calculate cross-entropy loss and accuracy. np.log() is the natural log.\n",
    "    digit = np.argmax(label)\n",
    "    loss = -np.log(out[digit])\n",
    "    acc = 1 if np.argmax(out) == digit else 0\n",
    "    return out, loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.11194977, 0.1017505 , 0.09059877, 0.1141039 , 0.08916559,\n",
       "        0.08113954, 0.10812428, 0.10109841, 0.09478553, 0.10728371]),\n",
       " 2.5115848634230615,\n",
       " 0)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward(train_images[0], train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(im, label, lr=0.01):\n",
    "    \"\"\"\n",
    "    前向传播->后向传播->更新梯度->计算损失及准确率\n",
    "    image: 2d numpy array\n",
    "    label: one-hot encoded digit\n",
    "    lr: learning rate\n",
    "    \"\"\"\n",
    "    # Forward\n",
    "    out, loss, acc = forward(im, label)\n",
    "\n",
    "    # Calculate initial gradient\n",
    "    digit = np.argmax(label)\n",
    "    gradient = np.zeros(10)\n",
    "    gradient[digit] = -1 / out[digit]\n",
    "\n",
    "    # Backprop\n",
    "    gradient = softmax.backprop(gradient, lr)\n",
    "    gradient = pool.backprop(gradient)\n",
    "    gradient = conv.backprop(gradient, lr)\n",
    "\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.314054444478007, 0)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(train_images[0], train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 1 ---\n",
      "[Step 100] Past 100 steps: Average Loss 2.304 | Accuracy: 14%\n",
      "[Step 200] Past 100 steps: Average Loss 2.310 | Accuracy: 10%\n",
      "[Step 300] Past 100 steps: Average Loss 2.313 | Accuracy: 9%\n",
      "[Step 400] Past 100 steps: Average Loss 2.311 | Accuracy: 11%\n",
      "[Step 500] Past 100 steps: Average Loss 2.300 | Accuracy: 12%\n",
      "[Step 600] Past 100 steps: Average Loss 2.319 | Accuracy: 7%\n",
      "[Step 700] Past 100 steps: Average Loss 2.317 | Accuracy: 7%\n",
      "[Step 800] Past 100 steps: Average Loss 2.308 | Accuracy: 6%\n",
      "[Step 900] Past 100 steps: Average Loss 2.320 | Accuracy: 11%\n",
      "[Step 1000] Past 100 steps: Average Loss 2.307 | Accuracy: 9%\n",
      "--- Epoch 2 ---\n",
      "[Step 100] Past 100 steps: Average Loss 2.299 | Accuracy: 7%\n",
      "[Step 200] Past 100 steps: Average Loss 2.309 | Accuracy: 10%\n",
      "[Step 300] Past 100 steps: Average Loss 2.322 | Accuracy: 11%\n",
      "[Step 400] Past 100 steps: Average Loss 2.305 | Accuracy: 11%\n",
      "[Step 500] Past 100 steps: Average Loss 2.314 | Accuracy: 6%\n",
      "[Step 600] Past 100 steps: Average Loss 2.317 | Accuracy: 8%\n",
      "[Step 700] Past 100 steps: Average Loss 2.304 | Accuracy: 15%\n",
      "[Step 800] Past 100 steps: Average Loss 2.329 | Accuracy: 14%\n",
      "[Step 900] Past 100 steps: Average Loss 2.310 | Accuracy: 13%\n",
      "[Step 1000] Past 100 steps: Average Loss 2.305 | Accuracy: 12%\n",
      "--- Epoch 3 ---\n",
      "[Step 100] Past 100 steps: Average Loss 2.285 | Accuracy: 14%\n",
      "[Step 200] Past 100 steps: Average Loss 2.324 | Accuracy: 9%\n",
      "[Step 300] Past 100 steps: Average Loss 2.303 | Accuracy: 14%\n",
      "[Step 400] Past 100 steps: Average Loss 2.322 | Accuracy: 8%\n",
      "[Step 500] Past 100 steps: Average Loss 2.307 | Accuracy: 11%\n",
      "[Step 600] Past 100 steps: Average Loss 2.304 | Accuracy: 10%\n",
      "[Step 700] Past 100 steps: Average Loss 2.320 | Accuracy: 14%\n",
      "[Step 800] Past 100 steps: Average Loss 2.328 | Accuracy: 9%\n",
      "[Step 900] Past 100 steps: Average Loss 2.302 | Accuracy: 12%\n",
      "[Step 1000] Past 100 steps: Average Loss 2.310 | Accuracy: 12%\n"
     ]
    }
   ],
   "source": [
    "# Train the CNN for 3 epochs\n",
    "for epoch in range(3):\n",
    "    print('--- Epoch %d ---' % (epoch + 1))\n",
    "    # Shuffle the training data\n",
    "    permutation = np.random.permutation(len(train_images))\n",
    "    train_images = train_images[permutation]\n",
    "    train_labels = train_labels[permutation]\n",
    "    # Train!\n",
    "    loss = 0\n",
    "    num_correct = 0\n",
    "    for i, (image, label) in enumerate(zip(train_images, train_labels)):\n",
    "        if i > 0 and i % 100 == 99:\n",
    "            print('[Step %d] Past 100 steps: Average Loss %.3f | Accuracy: %d%%' %(i + 1, loss / 100, num_correct))\n",
    "            loss = 0\n",
    "            num_correct = 0\n",
    "        out = conv.forward((image / 255.0) - 0.5)\n",
    "        out = pool.forward(out)\n",
    "        out = softmax.forward(out)\n",
    "        # Calculate cross-entropy loss and accuracy. np.log() is the natural log.\n",
    "        digit = np.argmax(label)\n",
    "        loss = -np.log(out[digit])\n",
    "        acc = 1 if np.argmax(out) == digit else 0\n",
    "            # Calculate initial gradient\n",
    "        gradient = np.zeros(10)\n",
    "        gradient[digit] = -1 / out[digit]\n",
    "        # Backprop\n",
    "        lr = 0.01\n",
    "        gradient = softmax.backprop(gradient, lr)\n",
    "        gradient = pool.backprop(gradient)\n",
    "        gradient = conv.backprop(gradient, lr)\n",
    "        loss += l\n",
    "        num_correct += acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo使用一千张图片做训练与测试， 可以使用全部的训练和测试图片，训练时间会比较久一些\n",
    "train_images = train_X.reshape(-1,28,28)[:1000]\n",
    "train_labels = train_Y[:1000]\n",
    "\n",
    "test_images = test_X.reshape(-1,28,28)[:1000]\n",
    "test_labels = test_Y[:1000]\n",
    "\n",
    "print(train_images.shape, train_labels.shape)\n",
    "print(test_images.shape, test_labels.shape)\n",
    "\n",
    "conv = ConvLayer(8,3,3,1)                  # 28x28x1 -> 26x26x8\n",
    "pool = MaxPoolingLayer(8,2,2,2)                  # 26x26x8 -> 13x13x8\n",
    "softmax = Softmax(13 * 13 * 8, 10) # 13x13x8 -> 10\n",
    "\n",
    "def forward(image, label):\n",
    "    \"\"\"\n",
    "    CNN 前向传播并计算 accuracy 与 cross-entropy loss.\n",
    "    - image： 2d numpy array\n",
    "    - label： one-hot encoded digit\n",
    "    \"\"\"\n",
    "    \n",
    "    # 将图片像素值从 [0, 255] 转换到 [-0.5, 0.5] ，这样更便于网络进行训练\n",
    "    out = conv.forward((image / 255) - 0.5)\n",
    "    out = pool.forward(out)\n",
    "    out = softmax.forward(out)\n",
    "\n",
    "    # Calculate cross-entropy loss and accuracy. np.log() is the natural log.\n",
    "    digit = np.argmax(label)\n",
    "    loss = -np.log(out[digit])\n",
    "    acc = 1 if np.argmax(out) == digit else 0\n",
    "    return out, loss, acc\n",
    "\n",
    "def train(im, label, lr=0.005):\n",
    "    \"\"\"\n",
    "    前向传播->后向传播->更新梯度->计算损失及准确率\n",
    "    image: 2d numpy array\n",
    "    label: one-hot encoded digit\n",
    "    lr: learning rate\n",
    "    \"\"\"\n",
    "    # Forward\n",
    "    out, loss, acc = forward(im, label)\n",
    "\n",
    "    # Calculate initial gradient\n",
    "    digit = np.argmax(label)\n",
    "    gradient = np.zeros(10)\n",
    "    gradient[digit] = -1 / out[digit]\n",
    "\n",
    "    # Backprop\n",
    "    gradient = softmax.backprop(gradient, lr)\n",
    "    gradient = pool.backprop(gradient)\n",
    "    gradient = conv.backprop(gradient, lr)\n",
    "\n",
    "    return loss, acc\n",
    "\n",
    "print('MNIST CNN initialized!')\n",
    "\n",
    "# Train the CNN for 3 epochs\n",
    "for epoch in range(3):\n",
    "    print('--- Epoch %d ---' % (epoch + 1))\n",
    "\n",
    "    # Shuffle the training data\n",
    "    permutation = np.random.permutation(len(train_images))\n",
    "    train_images = train_images[permutation]\n",
    "    train_labels = train_labels[permutation]\n",
    "\n",
    "    # Train!\n",
    "    loss = 0\n",
    "    num_correct = 0\n",
    "    for i, (im, label) in enumerate(zip(train_images, train_labels)):\n",
    "        if i > 0 and i % 100 == 99:\n",
    "            print('[Step %d] Past 100 steps: Average Loss %.3f | Accuracy: %d%%' %(i + 1, loss / 100, num_correct))\n",
    "            loss = 0\n",
    "            num_correct = 0\n",
    "\n",
    "        l, acc = train(im, label)\n",
    "        loss += l\n",
    "        num_correct += acc\n",
    "\n",
    "# Test the CNN\n",
    "print('\\n--- Testing the CNN ---')\n",
    "loss = 0\n",
    "num_correct = 0\n",
    "for im, label in zip(test_images, test_labels):\n",
    "    _, l, acc = forward(im, label)\n",
    "    loss += l\n",
    "    num_correct += acc\n",
    "\n",
    "num_tests = len(test_images)\n",
    "print('Test Loss:', loss / num_tests)\n",
    "print('Test Accuracy:', num_correct / num_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "train_images = mnist.train_images()\n",
    "train_labels = mnist.train_labels()\n",
    "test_images = mnist.test_images()\n",
    "test_labels = mnist.test_labels()\n",
    "\n",
    "train_images = (train_images / 255) - 0.5\n",
    "test_images = (test_images / 255) - 0.5\n",
    "\n",
    "train_images = np.expand_dims(train_images, axis=3)\n",
    "test_images = np.expand_dims(test_images, axis=3)\n",
    "\n",
    "model = Sequential([\n",
    "  Conv2D(8, 3, input_shape=(28, 28, 1), use_bias=False),\n",
    "  MaxPooling2D(pool_size=2),\n",
    "  Flatten(),\n",
    "  Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "model.compile(SGD(lr=.005), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(\n",
    "  train_images,\n",
    "  to_categorical(train_labels),\n",
    "  batch_size=1,\n",
    "  epochs=3,\n",
    "  validation_data=(test_images, to_categorical(test_labels)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
